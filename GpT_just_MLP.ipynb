{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO97xUGjJ/qTE1U6O8InT8P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohith202/Makemore_GPT/blob/main/GpT_just_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWDuYSTWwvAY",
        "outputId": "3b6ac742-4d2e-48cb-e397-d34883f34181"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'makemore'...\n",
            "remote: Enumerating objects: 64, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 64 (delta 20), reused 15 (delta 15), pack-reused 21 (from 1)\u001b[K\n",
            "Receiving objects: 100% (64/64), 123.28 KiB | 1.07 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/karpathy/makemore.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/makemore/names.txt\"\n",
        "\n",
        "content=None\n",
        "with open(file_path, 'r') as file:\n",
        "  content=file.read()"
      ],
      "metadata": {
        "id": "gNNoyBr2xphV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content=content.split(\"\\n\")"
      ],
      "metadata": {
        "id": "_mDYAL7QzG2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_encode={char:i for i,char in enumerate(list(set(\"\".join(content))))}\n",
        "char_to_encode[\".\"] = 26\n",
        "print(char_to_encode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vaGQBpSzLLJ",
        "outputId": "f742a6c5-88ac-42e3-cedc-37e7336d61f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'t': 0, 'i': 1, 'v': 2, 'o': 3, 'g': 4, 'y': 5, 'e': 6, 's': 7, 'm': 8, 'f': 9, 'n': 10, 'j': 11, 'l': 12, 'w': 13, 'b': 14, 'p': 15, 'x': 16, 'd': 17, 'u': 18, 'z': 19, 'a': 20, 'h': 21, 'c': 22, 'r': 23, 'q': 24, 'k': 25, '.': 26}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=10\n",
        "word_size=12\n",
        "weight_input = 24 # must be compatible with vie and word size\n",
        "weight_hidden = 12\n",
        "weight_output = 27\n",
        "resize_view = 24\n",
        "embeding_size =200\n",
        "epoch =100"
      ],
      "metadata": {
        "id": "9eK_FeiUVncs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "word_X=[]\n",
        "word_y=[]\n",
        "for word in content:\n",
        "  content_word=[26]*word_size\n",
        "  # print(word)\n",
        "  word=word+'.'\n",
        "  for letter in word:\n",
        "    word_X.append(content_word)\n",
        "    word_y.append(char_to_encode[letter])\n",
        "    content_word=content_word[1:] + [char_to_encode[letter]]\n",
        "\n",
        "\n",
        "print(word_X[:2],word_y[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzueFurc0Y5r",
        "outputId": "2d3f807c-bfa1-4735-fedf-e936885a65ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 6]] [6, 8, 8, 20, 26, 3, 12, 1, 2, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "word_length=len(word_X)\n",
        "\n",
        "indx=torch.randint(0,word_length,(batch_size,))\n",
        "batch_X = torch.tensor(word_X)[indx]\n",
        "batch_Y = torch.tensor(word_y)[indx]\n",
        "print(batch_X.shape,batch_Y.shape,batch_X[0])\n"
      ],
      "metadata": {
        "id": "fielill96bDV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3bd4b17-14ae-4b00-de73-79bc2b96a8b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 12]) torch.Size([10]) tensor([26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 22])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# batch_Y_emb =\n",
        "# print(\"Input batch Size:\",batch_X_emb.shape,\"and batch size of G.T is :\",batch_Y.shape)\n",
        "w = torch.randn((weight_input,embeding_size))\n",
        "b = torch.randn((embeding_size))\n",
        "w_1 = torch.randn(embeding_size,27)\n",
        "b_1 = torch.randn(27)\n",
        "embedding_C = torch.randn((27, 2))"
      ],
      "metadata": {
        "id": "Hwxl7nC-5IDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = [w,b,w_1,b_1]\n",
        "print(sum(p.nelement() for p in parameters))\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEuylbu2UqW2",
        "outputId": "98d18623-0f0f-40cc-d475-eb3863af1dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_batch_X.shape)\n",
        "print(embedding_C[batch_X[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQX0Iaj3dDyl",
        "outputId": "cff079d7-c26f-4c1b-b6d6-e4698316d7fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 12])\n",
            "tensor([[-0.5355,  0.8495],\n",
            "        [-0.5355,  0.8495],\n",
            "        [-0.5355,  0.8495],\n",
            "        [-0.5355,  0.8495],\n",
            "        [-0.5355,  0.8495],\n",
            "        [-0.5355,  0.8495],\n",
            "        [-0.5355,  0.8495],\n",
            "        [-0.5355,  0.8495],\n",
            "        [-0.5355,  0.8495],\n",
            "        [-0.5355,  0.8495],\n",
            "        [-0.5355,  0.8495],\n",
            "        [-0.6082, -0.3096]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "epoch =100\n",
        "\n",
        "y = torch.arange(0,27)\n",
        "\n",
        "\n",
        "for i in range(epoch):\n",
        "  indx=torch.randint(0,word_length,(batch_size,))\n",
        "  input_batch_X = torch.tensor(word_X)[indx]\n",
        "  input_batch_Y = torch.tensor(word_y)[indx]\n",
        "  batch_X_emb = embedding_C[batch_X]\n",
        "  # batch_X_emb = input_batch_X.to(torch.float32)\n",
        "  batch_X_emb = batch_X_emb.view(-1,resize_view)\n",
        "  h = torch.tanh(batch_X_emb @ w + b)\n",
        "  output = h@w_1 + b_1\n",
        "  # print(output,input_batch_Y)\n",
        "  loss = F.cross_entropy(output, input_batch_Y)\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "  for p in parameters:\n",
        "    p.data += -0.0000001 * p.grad\n",
        "\n",
        "  print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "L3AMbjdL3gsb",
        "outputId": "4a3fa63e-f5fe-4489-af05-15f3ea9ee634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38.96795654296875\n",
            "46.483680725097656\n",
            "30.279998779296875\n",
            "33.59212112426758\n",
            "32.539485931396484\n",
            "47.201393127441406\n",
            "43.237022399902344\n",
            "37.885074615478516\n",
            "41.122283935546875\n",
            "44.677947998046875\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-111-2208485783.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mindx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0minput_batch_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0minput_batch_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mbatch_X_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_C\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model(batch_X):\n",
        "    batch_X_emb = embedding_C[batch_X]\n",
        "    batch_X_emb = batch_X_emb.view(-1,12)\n",
        "    h = batch_X_emb @ w + b\n",
        "    h = torch.tanh(h)\n",
        "    output = h@w_1 + b_1\n",
        "    return output"
      ],
      "metadata": {
        "id": "HSiPI9a_4gJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indx=torch.randint(0,word_length,(batch_size,))\n",
        "input_batch_X = torch.tensor(word_X)[indx]\n",
        "input_batch_Y = torch.tensor(word_y)[indx]\n",
        "out = model(input_batch_X)\n",
        "loss = F.cross_entropy(out, input_batch_Y)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "gy7sz33zXCH2",
        "outputId": "3462e34a-2328-4c79-d3da-431e50f05bc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (20x12 and 24x50)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-91-2638639129.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minput_batch_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minput_batch_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_batch_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-83-4239115938.py\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(batch_X)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mbatch_X_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_C\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch_X_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_X_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_X_emb\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mw_1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (20x12 and 24x50)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-LjqiQMBX2Hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "9R4AiSEO5btX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "print(output.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hMUPxR1989f",
        "outputId": "99673bf8-f51a-4504-e9bf-4319a9c8238d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 27])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# print(output)\n"
      ],
      "metadata": {
        "id": "ImFdoVvo_cgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "id": "kpHf8kUN_eGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8hc9fTLCZjn",
        "outputId": "dac6ee36-a3b0-4943-9d5b-0c50f15c9bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.1648)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6MmyIWatChp3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}